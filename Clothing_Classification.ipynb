{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Clothing_Classification.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjQoihh1ibfT"
      },
      "source": [
        "# Clothing Classification \r\n",
        "**Purpose**:  \r\n",
        "Build and train a neural network to classify images of clothing. This model is trained on 60,000 images that include 10 types of articles of clothing.  \r\n",
        "\r\n",
        "Project based on [TensorFlow's classification example](https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l03c01_classifying_images_of_clothing.ipynb#scrollTo=DvYmmrpIy6Y1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vSehsP8k4RC"
      },
      "source": [
        "# install and import dependencies\r\n",
        "\r\n",
        "!pip install -U tensorflow_datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrjxYdVaiR8S"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "\r\n",
        "# import tensorflow datasets\r\n",
        "import tensorflow_datasets as tfds\r\n",
        "tfds.disable_progress_bar()\r\n",
        "\r\n",
        "# helper libraries\r\n",
        "import math\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "import logging\r\n",
        "logger = tf.get_logger()\r\n",
        "logger.setLevel(logging.ERROR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTr3mATnlFio"
      },
      "source": [
        "**Import the [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) dataset**  \r\n",
        "This dataset contains 70,000 grayscale images in ten categories, each in grayscale 28 x 28 pixel images.\r\n",
        "\r\n",
        "| Label | Description |\r\n",
        "| --- | --- |\r\n",
        "| 0 | T-shirt/top |\r\n",
        "| 1 | Trouser |\r\n",
        "| 2 | Pullover |\r\n",
        "| 3 | Dress |\r\n",
        "| 4 | Coat |\r\n",
        "| 5 | Sandal |\r\n",
        "| 6 | Shirt |\r\n",
        "| 7 | Sneaker |\r\n",
        "| 8 | Bag |\r\n",
        "| 9 | Ankle boot |\r\n",
        "\r\n",
        "This project uses the Fashion MNIST as a replacement for the classic MNIST dataset for variety and a slightly more challenging problem than the classic. The dataset is relatively small and is used to verify that the algorithm works as expected.\r\n",
        "\r\n",
        "\r\n",
        "Link to [Datasets API](https://www.tensorflow.org/datasets)\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uF_3AjxBmPlN"
      },
      "source": [
        "# import the Fashion MNIST dataset using the Datasets API\r\n",
        "dataset, metadata = tfds.load('fashion_mnist', as_supervised=True, with_info=True)\r\n",
        "train_dataset, test_dataset = dataset['train'], dataset['test']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4xhYB5wmCas"
      },
      "source": [
        "# store the class names for the image labels\r\n",
        "class_names = metadata.features['label'].names\r\n",
        "print(\"Class names:  {}\".format(class_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSRw8DS6m7rz"
      },
      "source": [
        "**Explore and preprocess the data**  \r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIA85qPKnFZV"
      },
      "source": [
        "# find the number of training and testing images\r\n",
        "num_train_examples = metadata.splits['train'].num_examples\r\n",
        "num_test_examples = metadata.splits['test'].num_examples\r\n",
        "print(\"Number of training examples: {}\".format(num_train_examples))\r\n",
        "print(\"Number of test examples:     {}\".format(num_test_examples))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wg3-xIX_olgs"
      },
      "source": [
        "# normalize the values of the pixels from the range [0,255] to [0,1]\r\n",
        "\r\n",
        "# create a normalization function and apply it to the datasets\r\n",
        "\r\n",
        "def normalize(images, labels):\r\n",
        "  images = tf.cast(images, tf.float32)\r\n",
        "  images /= 255\r\n",
        "  return images, labels\r\n",
        "\r\n",
        "train_dataset = train_dataset.map(normalize)\r\n",
        "test_dataset = test_dataset.map(normalize)\r\n",
        "\r\n",
        "# cache the datasets to keep them in memory after first load from disk\r\n",
        "train_dataset = train_dataset.cache()\r\n",
        "test_dataset = test_dataset.cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbWpsG9apCcR"
      },
      "source": [
        "# test plot for an image\r\n",
        "\r\n",
        "# take one image and remove the color dimension by reshaping the array\r\n",
        "for image, label in test_dataset.take(1):\r\n",
        "  break\r\n",
        "image = image.numpy().reshape((28,28))\r\n",
        "\r\n",
        "# plot the image\r\n",
        "plt.figure()\r\n",
        "plt.imshow(image, cmap=plt.cm.binary)\r\n",
        "plt.colorbar()\r\n",
        "plt.grid(False)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qDoYifTpWca"
      },
      "source": [
        "# display the first 25 images from the training set, display the class name, \r\n",
        "# and verify the data is in the correct format\r\n",
        "\r\n",
        "plt.figure(figsize=(10,10))\r\n",
        "for i, (image,label) in enumerate(test_dataset.take(25)):\r\n",
        "  image = image.numpy().reshape((28,28))\r\n",
        "  plt.subplot(5,5,i+1)\r\n",
        "  plt.xticks([])\r\n",
        "  plt.yticks([])\r\n",
        "  plt.grid(False)\r\n",
        "  plt.imshow(image, cmap=plt.cm.binary)\r\n",
        "  plt.xlabel(class_names[label])\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVtLh3mTqDdO"
      },
      "source": [
        "**Build the model**  \r\n",
        "\r\n",
        "Configure the layers and compile the model.  \r\n",
        "\r\n",
        "Layers:\r\n",
        "- **input - Flatten**: transforms the images from a 2D array of 28x28px to 1D of 784px. Reformats data.\r\n",
        "- **hidden - Dense**: densely connected layer of 128 neurons. Each neuron takes input from all 784 nodes in the previous layer, weighting that input according to learned hidden parameters and outputs a single value to the next layer\r\n",
        "- **output - Dense**: a 128-neuron followed by 10-node *softmax* layer, with each node representing a class of clothing. Takes input from the 128 nodes in the layer before it and outputs a value in the range [0,1] that represents the probability of an image belonging to the specified class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a76pikDAqwBE"
      },
      "source": [
        "# setup the layers\r\n",
        "\r\n",
        "model = tf.keras.Sequential([\r\n",
        "      tf.keras.layers.Flatten(input_shape=(28,28,1)),\r\n",
        "      tf.keras.layers.Dense(128, activation=tf.nn.relu),\r\n",
        "      tf.keras.layers.Dense(10, activation=tf.nn.softmax)\r\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zqwpc6O6sO-o"
      },
      "source": [
        "# compile the model\r\n",
        "\r\n",
        "# loss function: SparseCategoricalCrossentropy\r\n",
        "# optimizer: adam\r\n",
        "# metrics: accuracy\r\n",
        "\r\n",
        "model.compile(optimizer='adam',\r\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\r\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkD_vs8_slTB"
      },
      "source": [
        "**Train the model**  \r\n",
        "1. Define the iteration behavior\r\n",
        "- Repeat until specified epochs\r\n",
        "- Shuffle the order of examples\r\n",
        "- Use batches of 32 variables\r\n",
        "2. Train using the `model.fit` method\r\n",
        "- Feed the model the training data\r\n",
        "- Model learning go brr\r\n",
        "- Epochs limit training to 5 full iterations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoTEYcW-s8K9"
      },
      "source": [
        "BATCH_SIZE = 32\r\n",
        "train_dataset = train_dataset.cache().repeat().shuffle(num_train_examples).batch(BATCH_SIZE)\r\n",
        "test_dataset = test_dataset.cache().batch(BATCH_SIZE)\r\n",
        "\r\n",
        "model.fit(train_dataset, epochs=5, steps_per_epoch=math.ceil(num_train_examples/BATCH_SIZE))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuBFDzQBtheo"
      },
      "source": [
        "**Evaluate accuracy**  \r\n",
        "Accuracy on test_dataset is lower than accuracy on training, but this is normal! We can expect performance to go down."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwVuNTxKtj8T"
      },
      "source": [
        "# compare how the model performs on the test dataset\r\n",
        "\r\n",
        "test_loss, test_accuracy = model.evaluate(test_dataset, steps=math.ceil(num_test_examples/32))\r\n",
        "print('Accuracy on test dataset:', test_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKLFWudfuNny"
      },
      "source": [
        "**Make predictions**  \r\n",
        "Make some predictions about images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBy4LUEguRQJ"
      },
      "source": [
        "for test_images, test_labels in test_dataset.take(1):\r\n",
        "  test_images = test_images.numpy()\r\n",
        "  test_labels = test_labels.numpy()\r\n",
        "  predictions = model.predict(test_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEKv9GBiucui"
      },
      "source": [
        "predictions.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eob9JreZudHi"
      },
      "source": [
        "# full probability info\r\n",
        "predictions[0]\r\n",
        "\r\n",
        "# see which label has the highest confidence value\r\n",
        "np.argmax(predictions[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDETYhc4u3D7"
      },
      "source": [
        "test_labels[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDyTd7RQu5_o"
      },
      "source": [
        "# look at full set of class predictions\r\n",
        "def plot_image(i, predictions_array, true_labels, images):\r\n",
        "  predictions_array, true_label, img = predictions_array[i], true_labels[i], images[i]\r\n",
        "  plt.grid(False)\r\n",
        "  plt.xticks([])\r\n",
        "  plt.yticks([])\r\n",
        "\r\n",
        "  plt.imshow(img[...,0], cmap=plt.cm.binary)\r\n",
        "\r\n",
        "  predicted_label = np.argmax(predictions_array)\r\n",
        "  if predicted_label == true_label:\r\n",
        "    color = 'blue'\r\n",
        "  else:\r\n",
        "    color = 'red'\r\n",
        "\r\n",
        "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\r\n",
        "                                100*np.max(predictions_array),\r\n",
        "                                class_names[true_label]),\r\n",
        "                                color=color)\r\n",
        "  \r\n",
        "\r\n",
        "def plot_value_array(i, predictions_array, true_label):\r\n",
        "  predictions_array, true_label = predictions_array[i], true_label[i]\r\n",
        "  plt.grid(False)\r\n",
        "  plt.xticks([])\r\n",
        "  plt.yticks([])   \r\n",
        "  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\r\n",
        "  plt.ylim([0,1])\r\n",
        "  predicted_label = np.argmax(predictions_array)\r\n",
        "\r\n",
        "  thisplot[predicted_label].set_color('red')\r\n",
        "  thisplot[true_label].set_color('blue')\r\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhIImQRvw2oz"
      },
      "source": [
        "# look at the 0th image, predictions, and prediction array\r\n",
        "\r\n",
        "i = 0\r\n",
        "plt.figure(figsize=(6,3))\r\n",
        "plt.subplot(1,2,1)\r\n",
        "plot_image(i, predictions, test_labels, test_images)\r\n",
        "plt.subplot(1,2,2)\r\n",
        "plot_value_array(i, predictions, test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j05JUmNIxBAk"
      },
      "source": [
        "i = 12\r\n",
        "plt.figure(figsize=(6,3))\r\n",
        "plt.subplot(1,2,1)\r\n",
        "plot_image(i, predictions, test_labels, test_images)\r\n",
        "plt.subplot(1,2,2)\r\n",
        "plot_value_array(i, predictions, test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wy-PE0DmxgJ5"
      },
      "source": [
        "# use th trained model to make a prediction about a single image\r\n",
        "img = test_images[0]\r\n",
        "print(img.shape)\r\n",
        "\r\n",
        "# add image to a batch where it's the only member since tf.keras models are\r\n",
        "# optimized to make predictions on a batch/collection of examples at once\r\n",
        "img = np.array([img])\r\n",
        "print(img.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NShhqbQtxz8s"
      },
      "source": [
        "predictions_single = model.predict(img)\r\n",
        "\r\n",
        "print(predictions_single)\r\n",
        "\r\n",
        "plot_value_array(0, predictions_single, test_labels)\r\n",
        "_ = plt.xticks(range(10), class_names, rotation=45)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2PwfXlux-ng"
      },
      "source": [
        "np.argmax(predictions_single[0])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}