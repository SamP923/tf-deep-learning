{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dogs_vs_Cats_TransferLearning.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYcDOPth90VH"
      },
      "source": [
        "# Classify Images of Flowers\r\n",
        "**Purpose**:  \r\n",
        "Use transfer learning to classify images of cats and dogs using [TensorFlow Hub](https://www.tensorflow.org/hub), MobileNet models and the Dogs vs. Cats dataset.\r\n",
        "\r\n",
        "Concepts Covered:\r\n",
        "1. Use a TensorFlow Hub model for prediction\r\n",
        "2. Use a TensorFlow Hub model for Dogs vs. Cats dataset\r\n",
        "3. Do simple transfer learning with TensorFlow Hub\r\n",
        "\r\n",
        "Dataset Used: [Dogs vs Cats dataset](https://www.tensorflow.org/datasets/catalog/cats_vs_dogs)\r\n",
        "\r\n",
        "\r\n",
        "Project based on [TensorFlow's transfer learning example](https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l06c01_tensorflow_hub_and_transfer_learning.ipynb)\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auA_y1sr9tOR"
      },
      "source": [
        "# import tf and dependencies\r\n",
        "import tensorflow as tf\r\n",
        "import matplotlib.pylab as plt\r\n",
        "\r\n",
        "import tensorflow_hub as hub\r\n",
        "import tensorflow_datasets as tfds\r\n",
        "from tensorflow.keras import layers\r\n",
        "\r\n",
        "import logging\r\n",
        "logger = tf.get_logger()\r\n",
        "logger.setLevel(logging.ERROR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krTLTubJAhXk"
      },
      "source": [
        "# download the classifier\r\n",
        "CLASSIFIER_URL =\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/2\"\r\n",
        "IMAGE_RES = 224\r\n",
        "\r\n",
        "model = tf.keras.Sequential([\r\n",
        "    hub.KerasLayer(CLASSIFIER_URL, input_shape=(IMAGE_RES, IMAGE_RES, 3))\r\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qbqz4lEOBQKc"
      },
      "source": [
        "**Use a TensorFlow Hub MobileNet for prediction**  \r\n",
        "Take a trained model and load it into Keras\r\n",
        "1. Download the classifier\r\n",
        "2. Run on a single image\r\n",
        "3. Decode the predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsE702_UAjGu"
      },
      "source": [
        "# test if the model can work on a different output class\r\n",
        "import numpy as np\r\n",
        "import PIL.Image as Image\r\n",
        "\r\n",
        "grace_hopper = tf.keras.utils.get_file('image.jpg', 'https://storage.googleapis.com/download.tensorflow.org/example_images/grace_hopper.jpg')\r\n",
        "grace_hopper = Image.open(grace_hopper).resize((IMAGE_RES, IMAGE_RES))\r\n",
        "grace_hopper"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jb-aB7iRA0xF"
      },
      "source": [
        "grace_hopper = np.array(grace_hopper)/255.0\r\n",
        "grace_hopper.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlFT00ZdA41f"
      },
      "source": [
        "# add a batch dimension and pass the image to the model for prediction\r\n",
        "result = model.predict(grace_hopper[np.newaxis, ...])\r\n",
        "result.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbYr3Dy3A-rk"
      },
      "source": [
        "# ask for predicted class\r\n",
        "predicted_class = np.argmax(result[0], axis=-1)\r\n",
        "predicted_class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24_YFsSwBHqz"
      },
      "source": [
        "# decode the predictions\r\n",
        "labels_path = tf.keras.utils.get_file('ImageNetLabels.txt','https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt')\r\n",
        "imagenet_labels = np.array(open(labels_path).read().splitlines())\r\n",
        "\r\n",
        "plt.imshow(grace_hopper)\r\n",
        "plt.axis('off')\r\n",
        "predicted_class_name = imagenet_labels[predicted_class]\r\n",
        "_ = plt.title(\"Prediction: \" + predicted_class_name.title())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81p4rUTHFG8q"
      },
      "source": [
        "**Use a TensorFlow Hub model for the Dogs vs. Cats datset**  \r\n",
        "Use the full MobileNet model and see how it performs on the Dogs vs. Cats dataset\r\n",
        "1. Use TF Datasets to load the dataset\r\n",
        "2. Reformat images\r\n",
        "3. Run the classifier on a batch of images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bH04c4NFFGkj"
      },
      "source": [
        "# load Dogs vs. Cats dataset\r\n",
        "(train_examples, validation_examples), info = tfds.load(\r\n",
        "    'cats_vs_dogs',\r\n",
        "    with_info=True,\r\n",
        "    as_supervised=True,\r\n",
        "    split=['train[:80%]', 'train[80%:]']\r\n",
        ")\r\n",
        "\r\n",
        "num_examples = info.splits['train'].num_examples\r\n",
        "num_classes = info.features['label'].num_classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jL1n8hGLGaJd"
      },
      "source": [
        "# check the size of the images in the dataset\r\n",
        "def format_image(image, label):\r\n",
        "  image = tf.image.resize(image, (IMAGE_RES, IMAGE_RES))/255.0\r\n",
        "  return image, label\r\n",
        "\r\n",
        "BATCH_SIZE = 32\r\n",
        "\r\n",
        "train_batches      = train_examples.shuffle(num_examples//4).map(format_image).batch(BATCH_SIZE).prefetch(1)\r\n",
        "validation_batches = validation_examples.map(format_image).batch(BATCH_SIZE).prefetch(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pxhlgq_BGU23"
      },
      "source": [
        "# reformat images to the resolution expected by MobileNet\r\n",
        "def format_image(image, label):\r\n",
        "  image = tf.image.resize(image, (IMAGE_RES, IMAGE_RES))/255.0\r\n",
        "  return image, label\r\n",
        "\r\n",
        "BATCH_SIZE = 32\r\n",
        "\r\n",
        "train_batches      = train_examples.shuffle(num_examples//4).map(format_image).batch(BATCH_SIZE).prefetch(1)\r\n",
        "validation_batches = validation_examples.map(format_image).batch(BATCH_SIZE).prefetch(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B79LMiQzGgBx"
      },
      "source": [
        "# run the classifier on a batch of images\r\n",
        "image_batch, label_batch = next(iter(train_batches.take(1)))\r\n",
        "image_batch = image_batch.numpy()\r\n",
        "label_bacth = label_batch.numpy()\r\n",
        "\r\n",
        "result_batch = model.predict(image_batch)\r\n",
        "\r\n",
        "predicted_class_names = imagenet_labels[np.argmax(result_batch, axis=-1)]\r\n",
        "predicted_class_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXMXpE9vGtal"
      },
      "source": [
        "# plot function\r\n",
        "plt.figure(figsize=(10,9))\r\n",
        "for n in range(30):\r\n",
        "  plt.subplot(6,5,n+1)\r\n",
        "  plt.subplots_adjust(hspace = 0.3)\r\n",
        "  plt.imshow(image_batch[n])\r\n",
        "  plt.title(predicted_class_names[n])\r\n",
        "  plt.axis('off')\r\n",
        "\r\n",
        "_ = plt.suptitle(\"ImageNet predictions\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hLV8iZ3Fab1"
      },
      "source": [
        "**Do simple transfer learning with TensorFlow Hub**  \r\n",
        "Reuse parts of an already trained model and alter it to work with our own dataset.\r\n",
        "\r\n",
        "1. Extract and freeze the trained model\r\n",
        "2. Attach a classification head\r\n",
        "3. Train the model\r\n",
        "4. Check the predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGFXZR4xHSvi"
      },
      "source": [
        "# extract the dataset\r\n",
        "URL = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/2\"\r\n",
        "feature_extractor = hub.KerasLayer(URL,\r\n",
        "                                   input_shape=(IMAGE_RES, IMAGE_RES, 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Fw6vvAWHbAI"
      },
      "source": [
        "# run a batch of images through to see final shape (1290 neurons)\r\n",
        "feature_batch = feature_extractor(image_batch)\r\n",
        "print(feature_batch.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RS6nkUdCHg7F"
      },
      "source": [
        "# freeze the variables in the feature extractor layer\r\n",
        "feature_extractor.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9YEN9DbHnaF"
      },
      "source": [
        "# attach a classification head by wrapping the hub layer in a Sequential model\r\n",
        "# and adding a new classification layer\r\n",
        "\r\n",
        "model = tf.keras.Sequential([\r\n",
        "                             feature_extractor,\r\n",
        "                             layers.Dense(2)\r\n",
        "])\r\n",
        "\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6N1zDH7Hz2s"
      },
      "source": [
        "# train the model\r\n",
        "model.compile(\r\n",
        "    optimizer='adam',\r\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n",
        "    metrics=['accuracy']\r\n",
        ")\r\n",
        "EPOCHS = 6\r\n",
        "history = model.fit(train_batches,\r\n",
        "                    epochs=EPOCHS,\r\n",
        "                    validation_data=validation_batches)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_tCKkuhIGap"
      },
      "source": [
        "# plot the training and validation accuracy/loss graphs using matplot\r\n",
        "acc = history.history['accuracy']\r\n",
        "val_acc = history.history['val_accuracy']\r\n",
        "\r\n",
        "loss = history.history['loss']\r\n",
        "val_loss = history.history['val_loss']\r\n",
        "\r\n",
        "epochs_range = range(EPOCHS)\r\n",
        "\r\n",
        "# if validation performance > training performance, it's ok!\r\n",
        "# since we're reusing parts of the MobileNet dataset, it already includes \r\n",
        "# dog and cat images    \r\n",
        "# also, augmentation is only applied to the training images, not the\r\n",
        "# validation set ==> training images might be harder to classify than\r\n",
        "# images in the validation set\r\n",
        "\r\n",
        "plt.figure(figsize=(8,8))\r\n",
        "plt.subplot(1,2,1)\r\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\r\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\r\n",
        "plt.legend(loc='lower right')\r\n",
        "plt.title('Training and Validation Accuracy')\r\n",
        "\r\n",
        "plt.subplot(1, 2, 2)\r\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\r\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\r\n",
        "plt.legend(loc='upper right')\r\n",
        "plt.title('Training and Validation Loss')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtIAhK-nIx9x"
      },
      "source": [
        "# check predictions and redo the previous plot\r\n",
        "\r\n",
        "# get the ordered list of class names\r\n",
        "class_names = np.array(info.features['label'].names)\r\n",
        "class_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnwl-o8SI82V"
      },
      "source": [
        "# run the image batch through the model, convert indices to class names\r\n",
        "predicted_batch = model.predict(image_batch)\r\n",
        "predicted_batch = tf.squeeze(predicted_batch).numpy()\r\n",
        "predicted_ids = np.argmax(predicted_batch, axis=-1)\r\n",
        "predicted_class_names = class_names[predicted_ids]\r\n",
        "predicted_class_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7ldJ8IwJKYk"
      },
      "source": [
        "# look at true and predicted labels\r\n",
        "print(\"Labels: \", label_batch)\r\n",
        "print(\"Predicted labels: \", predicted_ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95fmjmTpJRfV"
      },
      "source": [
        "# plot\r\n",
        "plt.figure(figsize=(10,9))\r\n",
        "for n in range(30):\r\n",
        "  plt.subplot(6,5,n+1)\r\n",
        "  plt.subplots_adjust(hspace = 0.3)\r\n",
        "  plt.imshow(image_batch[n])\r\n",
        "  color = \"blue\" if predicted_ids[n] == label_batch[n] else \"red\"\r\n",
        "  plt.title(predicted_class_names[n].title(), color=color)\r\n",
        "  plt.axis('off')\r\n",
        "_ = plt.suptitle(\"Model predictions (blue: correct, red: incorrect)\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}