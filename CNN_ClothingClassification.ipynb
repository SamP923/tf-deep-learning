{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_ClothingClassification.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmyuozlbXYR2"
      },
      "source": [
        "# Clothing Classification with Convolutional Neural Networks\r\n",
        "**Purpose**:  \r\n",
        "Build and train a convolutional neural network (CNN) to classify images of clothing. This model is trained on 60,000 images that include 10 types of articles of clothing.  \r\n",
        "\r\n",
        "This project expands on the previous investigation into classifying clothing using neural networks, except we are now using convolutions for higher performance.\r\n",
        "\r\n",
        "Project based on [TensorFlow's classification example](https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l04c01_image_classification_with_cnns.ipynb)\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piiDNc1U0htI"
      },
      "source": [
        "**Install and import dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUXGtNK0XBKh"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXiuQWzq0kog"
      },
      "source": [
        "# import tensorflow datasets\r\n",
        "import tensorflow_datasets as tfds\r\n",
        "tfds.disable_progress_bar()\r\n",
        "\r\n",
        "import math\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8I3r3d_0xbF"
      },
      "source": [
        "import logging\r\n",
        "logger = tf.get_logger()\r\n",
        "logger.setLevel(logging.ERROR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UsXdI1101PC"
      },
      "source": [
        "**Import the Fashion MNIST dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fB-pfgzzmr-"
      },
      "source": [
        "# import the dataset from TensorFlow using the Datasets API\r\n",
        "dataset, metadata = tfds.load('fashion_mnist', as_supervised=True, with_info=True)\r\n",
        "train_dataset, test_dataset = dataset['train'], dataset['test']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckiOJZmTz3R6"
      },
      "source": [
        "# store the class names\r\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\r\n",
        "               'Sandal',      'Shirt',   'Sneaker',  'Bag',   'Ankle boot']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AhynZb70C1r"
      },
      "source": [
        "# find the number of training and testing images\r\n",
        "num_train_examples = metadata.splits['train'].num_examples\r\n",
        "num_test_examples = metadata.splits['test'].num_examples\r\n",
        "print(\"Number of training examples: {}\".format(num_train_examples))\r\n",
        "print(\"Number of test examples:     {}\".format(num_test_examples))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9GW55Aq0UdQ"
      },
      "source": [
        "**Preprocess the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UltRg1lA0ULI"
      },
      "source": [
        "# normalize the values of the pixels from the range [0,255] to [0,1]\r\n",
        "# create a normalization function and apply it to the datasets\r\n",
        "def normalize(images, labels):\r\n",
        "  images = tf.cast(images, tf.float32)\r\n",
        "  images /= 255\r\n",
        "  return images, labels\r\n",
        "\r\n",
        "train_dataset =  train_dataset.map(normalize)\r\n",
        "test_dataset  =  test_dataset.map(normalize)\r\n",
        "\r\n",
        "# cache the datasets to keep them in memory after first load from disk\r\n",
        "train_dataset = train_dataset.cache()\r\n",
        "test_dataset = test_dataset.cache()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzW2UQlI1FpU"
      },
      "source": [
        "**Build the model**  \r\n",
        "\r\n",
        "Configure the layers and compile the model.  \r\n",
        "Layers:\r\n",
        "\r\n",
        "*   **\"convolutions\":** Network starts with two pairs of `Conv2D`/`MaxPool`, with the first layer of Conv2D filters being applied to the input image and creating 32 output (convoluted images). The 32 outputs are then reduced in size using a MaxPooling of (2,2). The second layer of Conv2D filters uses a (3,3) kernel takes the 32 convoluted images and creates 64 outputs.\r\n",
        "*   **output-Dense:** A 128-neuron, followed by 10 node softmax layer, with each node representing a class of clothing\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMkmWWSq1HcS"
      },
      "source": [
        "# set up the layers by chaining two together\r\n",
        "\r\n",
        "model = tf.keras.Sequential([\r\n",
        "    tf.keras.layers.Conv2D(32, (3,3), padding='same', activation=tf.nn.relu,\r\n",
        "                           input_shape=(28,28,1)),\r\n",
        "    tf.keras.layers.MaxPooling2D((2,2), strides=2),\r\n",
        "    tf.keras.layers.Conv2D(64, (3,3), padding='same', activation=tf.nn.relu),\r\n",
        "    tf.keras.layers.MaxPooling2D((2,2), strides=2),\r\n",
        "    tf.keras.layers.Flatten(),\r\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\r\n",
        "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\r\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xys_J-wg2onx"
      },
      "source": [
        "# compile the model adding the loss function, optimizer, and metrics\r\n",
        "model.compile(optimizer='adam',\r\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\r\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BY1w58qY2tJo"
      },
      "source": [
        "**Train the model**  \r\n",
        "1. Define the iteration behavior\r\n",
        "- Repeat until specified epochs\r\n",
        "- Shuffle the order of examples\r\n",
        "- Use batches of 32 variables\r\n",
        "2. Train using the `model.fit` method\r\n",
        "- Feed the model the training data\r\n",
        "- Model learning go brr\r\n",
        "- Epochs limit training to 5 full iterations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76fOIVCi23t7"
      },
      "source": [
        "BATCH_SIZE = 32\r\n",
        "train_dataset = train_dataset.cache().repeat().shuffle(num_train_examples).batch(BATCH_SIZE)\r\n",
        "test_dataset = test_dataset.cache().batch(BATCH_SIZE)\r\n",
        "\r\n",
        "model.fit(train_dataset, epochs=5, steps_per_epoch=math.ceil(num_train_examples/BATCH_SIZE))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGgdG6SJ27Nw"
      },
      "source": [
        "**Evaluate accuracy**  \r\n",
        "Accuracy on test_dataset is lower than accuracy on training, but this is normal! We can expect performance to go down."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9z4LKYg27Bf"
      },
      "source": [
        "# compare how the model performs on the test dataset to the training data\r\n",
        "\r\n",
        "test_loss, test_accuracy = model.evaluate(test_dataset, steps=math.ceil(num_test_examples/32))\r\n",
        "print('Accuracy on test dataset:', test_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKlt4dMt3FA9"
      },
      "source": [
        "**Make predictions**  \r\n",
        "Make some predictions about images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uy3ENv-e2640"
      },
      "source": [
        "for test_images, test_labels in test_dataset.take(1):\r\n",
        "  test_images = test_images.numpy()\r\n",
        "  test_labels = test_labels.numpy()\r\n",
        "  predictions = model.predict(test_images)\r\n",
        "\r\n",
        "predictions.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPMyR1Lk3O0F"
      },
      "source": [
        "# full probability info\r\n",
        "predictions[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5lAg5Ik3Psh"
      },
      "source": [
        "# see which label has the highest confidence value\r\n",
        "np.argmax(predictions[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4TRBN223Wds"
      },
      "source": [
        "test_labels[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHMDSwRf3ar3"
      },
      "source": [
        "# look at full set of class predictions\r\n",
        "def plot_image(i, predictions_array, true_labels, images):\r\n",
        "  predictions_array, true_label, img = predictions_array[i], true_labels[i], images[i]\r\n",
        "  plt.grid(False)\r\n",
        "  plt.xticks([])\r\n",
        "  plt.yticks([])\r\n",
        "\r\n",
        "  plt.imshow(img[...,0], cmap=plt.cm.binary)\r\n",
        "\r\n",
        "  predicted_label = np.argmax(predictions_array)\r\n",
        "  if predicted_label == true_label:\r\n",
        "    color = 'blue'\r\n",
        "  else:\r\n",
        "    color = 'red'\r\n",
        "\r\n",
        "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\r\n",
        "                                100*np.max(predictions_array),\r\n",
        "                                class_names[true_label]),\r\n",
        "                                color=color)\r\n",
        "  \r\n",
        "\r\n",
        "def plot_value_array(i, predictions_array, true_label):\r\n",
        "  predictions_array, true_label = predictions_array[i], true_label[i]\r\n",
        "  plt.grid(False)\r\n",
        "  plt.xticks([])\r\n",
        "  plt.yticks([])   \r\n",
        "  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\r\n",
        "  plt.ylim([0,1])\r\n",
        "  predicted_label = np.argmax(predictions_array)\r\n",
        "\r\n",
        "  thisplot[predicted_label].set_color('red')\r\n",
        "  thisplot[true_label].set_color('blue')\r\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCBelxGZ3dut"
      },
      "source": [
        "# look at the 0th image, predictions, and prediction array\r\n",
        "\r\n",
        "i = 0\r\n",
        "plt.figure(figsize=(6,3))\r\n",
        "plt.subplot(1,2,1)\r\n",
        "plot_image(i, predictions, test_labels, test_images)\r\n",
        "plt.subplot(1,2,2)\r\n",
        "plot_value_array(i, predictions, test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wq1ZuHQa3fpW"
      },
      "source": [
        "i = 12\r\n",
        "plt.figure(figsize=(6,3))\r\n",
        "plt.subplot(1,2,1)\r\n",
        "plot_image(i, predictions, test_labels, test_images)\r\n",
        "plt.subplot(1,2,2)\r\n",
        "plot_value_array(i, predictions, test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBp9V2BG3nxW"
      },
      "source": [
        "# plot the first X test images, their predicted label, and the true label\r\n",
        "# color correct predictions in blue, incorrect predictions in red to give\r\n",
        "# percent for the predicted label\r\n",
        "\r\n",
        "num_rows = 5\r\n",
        "num_cols = 3\r\n",
        "num_images = num_rows*num_cols\r\n",
        "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\r\n",
        "\r\n",
        "for i in range(num_images):\r\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\r\n",
        "  plot_image(i, predictions, test_labels, test_images)\r\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\r\n",
        "  plot_value_array(i, predictions, test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndcYGA1o4FUq"
      },
      "source": [
        "# use the trained model to make a prediction about a single image\r\n",
        "img = test_images[0]\r\n",
        "print(img.shape)\r\n",
        "\r\n",
        "# add image to a batch where it's the only member since tf.keras models are\r\n",
        "# optimized to make predictions on a batch/collection of examples at once\r\n",
        "img = np.array([img])\r\n",
        "print(img.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlsNupux4KkS"
      },
      "source": [
        "predictions_single = model.predict(img)\r\n",
        "\r\n",
        "print(predictions_single)\r\n",
        "\r\n",
        "plot_value_array(0, predictions_single, test_labels)\r\n",
        "_ = plt.xticks(range(10), class_names, rotation=45)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkKfHOyt4RZq"
      },
      "source": [
        "np.argmax(predictions_single[0])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}